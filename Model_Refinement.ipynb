{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_Refinement.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "agHE00O6iJ_8",
        "UMU866MQVMI8",
        "wwKAQEljYPpY"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRbIh8Y4TzJM"
      },
      "source": [
        "# Out-of-Distribution Detection for Model Refinement in Cardiac Image Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klo7sbw-Pq4A"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rO6Nge87U-GD"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agHE00O6iJ_8"
      },
      "source": [
        "## Install requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lu9mp3A-iMs1"
      },
      "source": [
        "#### megatools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXvS-CbkiOyo"
      },
      "source": [
        "!sudo apt-get install megatools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoUFHZx8qLje"
      },
      "source": [
        "#### batchgenerators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMpIgch7p2ks"
      },
      "source": [
        "!pip install --upgrade batchgenerators"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzgnSeAIqJj6"
      },
      "source": [
        "#### medpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dwE4hvyp2h1"
      },
      "source": [
        "!pip install medpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1f_kgr-BNmb"
      },
      "source": [
        "#### nibabel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "app4iyyBgQRS"
      },
      "source": [
        "!pip install nibabel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMU866MQVMI8"
      },
      "source": [
        "## Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4Z259wuVWVY"
      },
      "source": [
        "!git clone https://github.com/manigalati/MnMs2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "118Y-3S6WtwB"
      },
      "source": [
        "%cd /content/MnMs2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyIrl-LeVM_i"
      },
      "source": [
        "!megadl \"https://mega.nz/#!RERgEZhK!C9SXLaRV6Ep3pRn5ips_rGLsHUxP9wDZeJlBOSY6Af4\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9B2laLJXC-0"
      },
      "source": [
        "!mkdir data\n",
        "#MnMs2 dataset\n",
        "!python gdrivedl.py https://drive.google.com/open?id=1-18mR3kwzErkqeTDZ-_UzQtalvnYK1fD data/\n",
        "#vendor information\n",
        "!python gdrivedl.py https://drive.google.com/open?id=1B8Rv0xGExxEahnYE7LMx0MeiJVXdaDPM data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxYTfkbJXEjl"
      },
      "source": [
        "!unrar e data/MnM-2.rar data/\n",
        "!rm data/MnM-2.rar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwKAQEljYPpY"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M23L1vUnL8i7"
      },
      "source": [
        "import os\n",
        "from utils import get_vendor_info\n",
        "from utils import get_splits\n",
        "from utils import generate_patient_info, crop_image\n",
        "from utils import preprocess, preprocess_image, inSplit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NO6Pw4cZe80"
      },
      "source": [
        "The challenge cohort was composed of 360 patients with different rigth ventricle and left ventricle pathologies as well as healthy subjects. All subjects were scanned in four clinical centres in two different countries (Spain, Germany) using four different magnetic resonance scanner vendors (Siemens, General Electric and Philips )."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0FjNeoTaiFJ"
      },
      "source": [
        "The training set contained 200 annotated images from four different centres. The CMR images have been segmented by experienced clinicians from the respective institutions, including contours for the left (LV) and right ventricle (RV) blood pools, as well as for the left ventricular myocardium (MYO). Labels are: 1 (LV), 2 (MYO) and 3 (RV) in both short-axis and long-axis views with a variety of difficult RV pathologies and remodelling as well as LV pathologies. This year we will focus on RV segmentation. Labels 1 and 2 will be provided but will not score in the final challenge results. 40 cases, 5 for each pathology, will be used to create a public leaderboard and will be added to the final testing set. Two pathologies (Tricuspidal Regurgitation and Congenital Arrhythmogenesis) will be not present in the training set but in the validation and testing sets to evaluate generalisation to unseen pathologies.\n",
        "\n",
        "<table style=\"width:70%; margin: auto\">\n",
        "        <tbody><tr>\n",
        "            <th>Pathology</th><th>Num. studies training</th> <th>Num. studies validation</th>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td style=\"text-align:left\">Normal subjects</td><td>40</td><td>5</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td style=\"text-align:left\">Dilated Left Ventricle</td><td>30</td><td>5</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td style=\"text-align:left\">Hypertrophic Cardiomyopathy</td><td>30</td><td>5</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td style=\"text-align:left\">Congenital Arrhythmogenesis</td><td>20</td><td>5</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td style=\"text-align:left\">Tetralogy of Fallot</td><td>20</td><td>5</td>\n",
        "        </tr>\n",
        "        <tr>      \n",
        "            <td style=\"text-align:left\">Interatrial Comunication</td><td>20</td><td>5</td>\n",
        "        </tr>\n",
        "        <tr>       \n",
        "            <td style=\"text-align:left\">Dilated Right Ventricle</td><td>0</td><td>5</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td style=\"text-align:left\">Tricuspidal Regurgitation</td><td>0</td><td>5</td>\n",
        "        </tr>\n",
        "</tbody></table>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzYvA3nhKJWS"
      },
      "source": [
        "vendor_info = get_vendor_info(\"data/MNM2_vendor_information_training_set.csv\")\n",
        "vendor_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL1D2nTVZ4KV"
      },
      "source": [
        "vendor_info[['VENDOR','SUBJECT_CODE']].groupby(['VENDOR']).count().rename(columns={'SUBJECT_CODE':'NUM_STUDIES'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUh9sk2JKa2K"
      },
      "source": [
        "if not os.path.isdir(\"preprocessed\"):\n",
        "    os.makedirs(\"preprocessed\")\n",
        "splits = get_splits(os.path.join(\"preprocessed\", \"splits.pkl\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s64B5vuyd4kj"
      },
      "source": [
        "patient_info = generate_patient_info(vendor_info, os.path.join(\"preprocessed\", \"patient_info.pkl\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqOCPaH0hHpy"
      },
      "source": [
        "spacings = [\n",
        "    patient_info[\"{:03d}_{}\".format(id, axis)][\"spacing\"] for axis in [\"SA\", \"LA\"] for id in (\n",
        "        splits[\"train\"][\"lab\"] + splits[\"train\"][\"ulab\"] + splits[\"val\"]\n",
        "    )\n",
        "]\n",
        "spacing_target = np.percentile(np.vstack(spacings), 50, 0)\n",
        "\n",
        "if not os.path.isdir(\"preprocessed/training/labelled\"): os.makedirs(\"preprocessed/training/labelled\")\n",
        "if not os.path.isdir(\"preprocessed/training/unlabelled\"): os.makedirs(\"preprocessed/training/unlabelled\")\n",
        "if not os.path.isdir(\"preprocessed/validation/\"): os.makedirs(\"preprocessed/validation/\")\n",
        "if not os.path.isdir(\"preprocessed/soft_validation/\"): os.makedirs(\"preprocessed/soft_validation/\")\n",
        "if not os.path.isdir(\"preprocessed/testing/\"): os.makedirs(\"preprocessed/testing/\")\n",
        "\n",
        "preprocess(\n",
        "    {k:v for k,v in patient_info.items() if inSplit(k, splits[\"train\"][\"lab\"])},\n",
        "    spacing_target, \"preprocessed/training/labelled/\"\n",
        ")\n",
        "preprocess(\n",
        "    {k:v for k,v in patient_info.items() if inSplit(k, splits[\"train\"][\"ulab\"])},\n",
        "    spacing_target, \"preprocessed/training/unlabelled/\"\n",
        ")\n",
        "preprocess(\n",
        "    {k:v for k,v in patient_info.items() if inSplit(k, splits[\"val\"])},\n",
        "    spacing_target, \"preprocessed/validation/\"\n",
        ")\n",
        "preprocess(\n",
        "    {k:v for k,v in patient_info.items() if inSplit(k, splits[\"val\"])},\n",
        "    spacing_target, \"preprocessed/soft_validation/\", soft_preprocessing=True\n",
        ")\n",
        "preprocess(\n",
        "    {k:v for k,v in patient_info.items() if inSplit(k, splits[\"test\"])},\n",
        "    spacing_target, \"preprocessed/testing/\", soft_preprocessing=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGnU1zxqA9LJ"
      },
      "source": [
        "## $\\mathcal{M}$ - Supervised Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLlIj-X1XU3n"
      },
      "source": [
        "import torch.nn as nn\n",
        "import os\n",
        "import torch\n",
        "\n",
        "from baseline_1 import Baseline_1\n",
        "from baseline_2 import Baseline_2\n",
        "from utils import AttrDict\n",
        "from utils import GDLoss, CELoss\n",
        "from utils import device\n",
        "from utils import Validator, Checkpointer\n",
        "from utils import supervised_training\n",
        "from utils import ACDCDataLoader, ACDCAllPatients\n",
        "from utils import BATCH_SIZE, EPOCHS\n",
        "from utils import transform_augmentation_downsample, transform\n",
        "from utils import plot_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUN04QLwIccq"
      },
      "source": [
        "Model = Baseline_2\n",
        "\n",
        "model = nn.ModuleDict([\n",
        "    [axis, Model(\n",
        "        AttrDict(**{\n",
        "            \"lr\": 0.01,\n",
        "            \"functions\": [GDLoss, CELoss]\n",
        "        })\n",
        "    )] for axis in [\"SA\", \"LA\"]\n",
        "]).to(device)\n",
        "\n",
        "ckpts = None\n",
        "if ckpts is not None:\n",
        "    for axis, ckpt in ckpts.items():\n",
        "        _, start = os.path.split(ckpt)\n",
        "        start = int(start.replace(\".pth\", \"\"))\n",
        "        ckpt = torch.load(ckpt)\n",
        "        model[axis].load_state_dict(ckpt[\"M\"])\n",
        "        model[axis].optimizer.load_state_dict(ckpt[\"M_optim\"])\n",
        "else:\n",
        "    start = 1\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkQijdvTIccr"
      },
      "source": [
        "validators = {\n",
        "    \"SA\": Validator(5),\n",
        "    \"LA\": Validator(5)\n",
        "}\n",
        "\n",
        "for axis in [\"SA\", \"LA\"]:\n",
        "    supervised_training(\n",
        "        model[axis],\n",
        "        range(start, 5), #EPOCHS\n",
        "        torch.utils.data.DataLoader(\n",
        "            ACDCAllPatients(\n",
        "                os.path.join(\"preprocessed/training/labelled/\", axis),\n",
        "                transform=transform_augmentation_downsample\n",
        "            ),\n",
        "            batch_size=BATCH_SIZE, shuffle=False, num_workers=0\n",
        "        ),\n",
        "        ACDCDataLoader(\n",
        "            os.path.join(\"preprocessed/validation/\", axis),\n",
        "            batch_size=BATCH_SIZE, transform=transform\n",
        "        ),\n",
        "        validators[axis],\n",
        "        Checkpointer(os.path.join(\"checkpoints/M\", axis))\n",
        "    )\n",
        "\n",
        "    plot_history(validators[axis].get_history(\"val\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYiWN1oReZ7x"
      },
      "source": [
        "## $\\mathcal{M}$ - Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddkyuO4xrh4Z"
      },
      "source": [
        "import torch.nn as nn\n",
        "import os\n",
        "import torch\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "from baseline_1 import Baseline_1\n",
        "from baseline_2 import Baseline_2\n",
        "from utils import device\n",
        "from utils import ACDCDataLoader\n",
        "from utils import BATCH_SIZE\n",
        "from utils import transform\n",
        "from utils import infer_predictions\n",
        "from utils import get_splits\n",
        "from utils import postprocess_predictions, display_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cC4-lDxh69HS"
      },
      "source": [
        "Model = Baseline_2\n",
        "\n",
        "model = nn.ModuleDict([\n",
        "    [axis, Model()] for axis in [\"SA\", \"LA\"]\n",
        "]).to(device)\n",
        "\n",
        "for axis in [\"SA\", \"LA\"]:\n",
        "    ckpt = os.path.join(\"checkpoints/M\", axis, \"best_000.pth\")\n",
        "    model[axis].load_state_dict(torch.load(ckpt)[\"M\"])\n",
        "    model[axis].to(device)\n",
        "    model.eval()\n",
        "\n",
        "    infer_predictions(\n",
        "        os.path.join(\"inference\", axis),\n",
        "        ACDCDataLoader(\n",
        "            f\"preprocessed/testing/{axis}\",\n",
        "            batch_size = BATCH_SIZE,\n",
        "            transform = transform,\n",
        "            transform_gt = False\n",
        "        ),\n",
        "        model[axis]\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiCiQWb3qwBa"
      },
      "source": [
        "splits = get_splits(os.path.join(\"checkpoints\", \"splits.pkl\"))\n",
        "\n",
        "with open(os.path.join(\"preprocessed\", \"patient_info.pkl\"),'rb') as f:\n",
        "    patient_info = pickle.load(f)\n",
        "\n",
        "spacings = [\n",
        "    patient_info[\"{:03d}_{}\".format(id, axis)][\"spacing\"] for axis in [\"SA\", \"LA\"] for id in (\n",
        "        splits[\"train\"][\"lab\"] + splits[\"train\"][\"ulab\"] + splits[\"val\"]\n",
        "    )\n",
        "]\n",
        "\n",
        "current_spacing = np.percentile(np.vstack(spacings), 50, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riA9pT18GcNH"
      },
      "source": [
        "results = {}\n",
        "for axis in [\"SA\", \"LA\"]:\n",
        "    results[axis] = postprocess_predictions(\n",
        "        os.path.join(\"inference\", axis),\n",
        "        patient_info,\n",
        "        current_spacing,\n",
        "        os.path.join(\"postprocessed\", axis),\n",
        "    )\n",
        "\n",
        "display_results(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mck6Rojezw3K"
      },
      "source": [
        "## $\\mathcal{R}$ - Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkOhOgQbJKQS"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import os\n",
        "\n",
        "from reconstructor import Reconstructor\n",
        "from utils import AttrDict\n",
        "from utils import device\n",
        "from utils import plot_history\n",
        "from utils import ACDCAllPatients, ACDCDataLoader\n",
        "from utils import transform\n",
        "from utils import BATCH_SIZE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI3sXcUHBufa"
      },
      "source": [
        "ae = nn.ModuleDict([\n",
        "    [axis, Reconstructor(\n",
        "        AttrDict(**{\n",
        "            \"latent_size\": 100,\n",
        "            \"lr\": 2e-4,\n",
        "            \"last_layer\": [4,2,1],\n",
        "            \"in_channels\": 4,\n",
        "            \"weighted_epochs\": 0\n",
        "        })\n",
        "    )] for axis in [\"SA\", \"LA\"]\n",
        "]).to(device)\n",
        "\n",
        "ckpts = None\n",
        "if ckpts is not None:\n",
        "    for axis, ckpt in ckpts.items():\n",
        "        _, start = os.path.split(ckpt)\n",
        "        start = int(start.replace(\".pth\", \"\"))\n",
        "        ckpt = torch.load(ckpt)\n",
        "        ae[axis].load_state_dict(ckpt[\"R\"])\n",
        "        ae[axis].optimizer.load_state_dict(ckpt[\"R_optim\"])\n",
        "else:\n",
        "    start = 0\n",
        "print(ae)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k94SEyHnCg8i"
      },
      "source": [
        "for axis in [\"SA\", \"LA\"]:\n",
        "    plot_history(ae[axis].training_routine(\n",
        "        range(start, 5),#500\n",
        "        torch.utils.data.DataLoader(\n",
        "            ACDCAllPatients(\n",
        "                os.path.join(\"preprocessed/training/labelled/\", axis),\n",
        "                transform=transform\n",
        "            ),\n",
        "            batch_size=BATCH_SIZE, shuffle=False, num_workers=0\n",
        "        ),\n",
        "        ACDCDataLoader(\n",
        "            os.path.join(\"preprocessed/validation/\", axis),\n",
        "            batch_size=BATCH_SIZE, transform=transform\n",
        "        ),\n",
        "        os.path.join(\"checkpoints/R/\", axis)\n",
        "    ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4Lt1kRGd2v8"
      },
      "source": [
        "## QC-based Candidate Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP_jUix7s90c"
      },
      "source": [
        "import torch.nn as nn\n",
        "import os\n",
        "import torch\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "from baseline_1 import Baseline_1\n",
        "from baseline_2 import Baseline_2\n",
        "from reconstructor import Reconstructor\n",
        "from utils import device\n",
        "from utils import AttrDict\n",
        "from utils import Validator\n",
        "from utils import ACDCDataLoader\n",
        "from utils import BATCH_SIZE\n",
        "from utils import transform\n",
        "from utils import GDLoss, CELoss, GDLoss_RV, CELoss_RV\n",
        "from utils import infer_predictions\n",
        "from utils import get_splits\n",
        "from utils import postprocess_predictions\n",
        "from utils import display_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEEX2Xh2gugu"
      },
      "source": [
        "Model = Baseline_2\n",
        "\n",
        "model = nn.ModuleDict([\n",
        "    [axis, Model(\n",
        "        AttrDict(**{\n",
        "            \"lr\": 0.01,\n",
        "            \"functions\": [GDLoss, CELoss],\n",
        "            \"functions_RV\": [GDLoss_RV, CELoss_RV]\n",
        "        })\n",
        "    )] for axis in [\"SA\", \"LA\"]\n",
        "]).to(device)\n",
        "\n",
        "ae = nn.ModuleDict([\n",
        "    [axis, Reconstructor(\n",
        "        AttrDict(**{\n",
        "            \"latent_size\": 100,\n",
        "            \"lr\": 2e-4,\n",
        "            \"last_layer\": [4,2,1],\n",
        "            \"in_channels\": 4,\n",
        "            \"weighted_epochs\": 0\n",
        "        })\n",
        "    )] for axis in [\"SA\", \"LA\"]\n",
        "]).to(device)\n",
        "\n",
        "validators = {\n",
        "    \"SA\": Validator(5),\n",
        "    \"LA\": Validator(5)\n",
        "}\n",
        "\n",
        "for axis in [\"SA\", \"LA\"]:\n",
        "    ckpt = os.path.join(\"checkpoints/R\", axis)\n",
        "    ckpt = os.path.join(ckpt, sorted([file for file in os.listdir(ckpt) if \"_best\" in file])[-1])\n",
        "    ckpt = torch.load(ckpt)\n",
        "    ae[axis].load_state_dict(ckpt[\"R\"])\n",
        "    ae.eval()\n",
        "    \n",
        "    for file in os.listdir(os.path.join(\"checkpoints/M\", axis)):\n",
        "        if \"best_\" not in file:\n",
        "            continue\n",
        "        ckpt = torch.load(os.path.join(\"checkpoints/M\", axis, file))\n",
        "        model[axis].load_state_dict(ckpt[\"M\"])\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            validators[axis].domain_evaluation(\n",
        "                \"test\",\n",
        "                model[axis],\n",
        "                ACDCDataLoader(\n",
        "                    f\"preprocessed/testing/{axis}\",\n",
        "                    batch_size = BATCH_SIZE,\n",
        "                    transform = transform,\n",
        "                    transform_gt = False\n",
        "                ),    \n",
        "                reconstructor=ae[axis]\n",
        "            )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I83-gFmKi2K0"
      },
      "source": [
        "for axis in [\"SA\", \"LA\"]:\n",
        "    infer_predictions(\n",
        "        os.path.join(\"inference\", axis),\n",
        "        ACDCDataLoader(\n",
        "            f\"preprocessed/testing/{axis}\",\n",
        "            batch_size = BATCH_SIZE,\n",
        "            transform = transform,\n",
        "            transform_gt = False\n",
        "        ),\n",
        "        validator=validators[axis]\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plW3jkpK1Avl"
      },
      "source": [
        "splits = get_splits(os.path.join(\"checkpoints\", \"splits.pkl\"))\n",
        "\n",
        "with open(os.path.join(\"preprocessed\", \"patient_info.pkl\"),'rb') as f:\n",
        "    patient_info = pickle.load(f)\n",
        "\n",
        "spacings = [\n",
        "    patient_info[\"{:03d}_{}\".format(id, axis)][\"spacing\"] for axis in [\"SA\", \"LA\"] for id in (\n",
        "        splits[\"train\"][\"lab\"] + splits[\"train\"][\"ulab\"] + splits[\"val\"]\n",
        "    )\n",
        "]\n",
        "\n",
        "current_spacing = np.percentile(np.vstack(spacings), 50, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzHrTP9f1Avm"
      },
      "source": [
        "results = {}\n",
        "for axis in [\"SA\", \"LA\"]:\n",
        "    results[axis] = postprocess_predictions(\n",
        "        os.path.join(\"inference\", axis),\n",
        "        patient_info,\n",
        "        current_spacing,\n",
        "        os.path.join(\"postprocessed\", axis),\n",
        "    )\n",
        "\n",
        "display_results(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTI3Ijujuw2q"
      },
      "source": [
        "## Semi-Supervised Refinement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQLB6Orh3w3R"
      },
      "source": [
        "import torch.nn as nn\n",
        "import os\n",
        "import torch\n",
        "\n",
        "from baseline_1 import Baseline_1\n",
        "from baseline_2 import Baseline_2\n",
        "from reconstructor import Reconstructor\n",
        "from utils import AttrDict\n",
        "from utils import GDLoss, CELoss, GDLoss_RV, CELoss_RV\n",
        "from utils import device\n",
        "from utils import Validator, Checkpointer\n",
        "from utils import semisupervised_refinement\n",
        "from utils import ACDCDataLoader, ACDCAllPatients\n",
        "from utils import BATCH_SIZE, EPOCHS\n",
        "from utils import transform_augmentation_downsample, transform\n",
        "from utils import plot_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2ufEsPL36KQ"
      },
      "source": [
        "#TODO: checkpoint should save also validator informations\n",
        "\n",
        "Model = Baseline_2\n",
        "\n",
        "model = nn.ModuleDict([\n",
        "    [axis, Model(\n",
        "        AttrDict(**{\n",
        "            \"lr\": 0.01,\n",
        "            \"functions\": [GDLoss, CELoss],\n",
        "            \"functions_RV\": [GDLoss_RV, CELoss_RV]\n",
        "        })\n",
        "    )] for axis in [\"SA\", \"LA\"]\n",
        "]).to(device)\n",
        "\n",
        "ae = nn.ModuleDict([\n",
        "    [axis, Reconstructor(\n",
        "        AttrDict(**{\n",
        "            \"latent_size\": 100,\n",
        "            \"lr\": 2e-4,\n",
        "            \"last_layer\": [4,2,1],\n",
        "            \"in_channels\": 4,\n",
        "            \"weighted_epochs\": 0\n",
        "        })\n",
        "    )] for axis in [\"SA\", \"LA\"]\n",
        "]).to(device)\n",
        "\n",
        "ckpts = None#TODO: here ckpts should be compulsory, also with the autoencoder\n",
        "if ckpts is not None:\n",
        "    for axis, ckpt in ckpts.items():\n",
        "        _, start = os.path.split(ckpt)\n",
        "        start = int(start.replace(\".pth\", \"\"))\n",
        "        ckpt = torch.load(ckpt)\n",
        "        model[axis].load_state_dict(ckpt[\"M\"])\n",
        "        model[axis].optimizer.load_state_dict(ckpt[\"M_optim\"])\n",
        "else:\n",
        "    start = 1\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCLDL5gxP-PD"
      },
      "source": [
        "validators = {\n",
        "    \"SA\": Validator(5),\n",
        "    \"LA\": Validator(5)\n",
        "}\n",
        "\n",
        "for axis in [\"SA\", \"LA\"]:\n",
        "    semisupervised_refinement(\n",
        "        model[axis],\n",
        "        ae[axis],\n",
        "        range(start, 5),#200\n",
        "        torch.utils.data.DataLoader(\n",
        "            ACDCAllPatients(\n",
        "                os.path.join(\"preprocessed/training/labelled/\", axis),\n",
        "                transform=transform_augmentation_downsample\n",
        "            ),\n",
        "            batch_size=BATCH_SIZE, shuffle=False, num_workers=0\n",
        "        ),\n",
        "        ACDCDataLoader(\n",
        "            os.path.join(\"preprocessed/validation/\", axis),\n",
        "            batch_size=BATCH_SIZE, transform=transform\n",
        "        ),\n",
        "        ACDCDataLoader(\n",
        "            os.path.join(\"preprocessed/training/unlabelled/\", axis),\n",
        "            batch_size = BATCH_SIZE, transform=transform\n",
        "        ),\n",
        "        validators[axis],\n",
        "        Checkpointer(os.path.join(\"checkpoints/M_refinement\", axis))\n",
        "    )\n",
        "\n",
        "    plot_history(validators[axis].get_history(\"val\"))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}